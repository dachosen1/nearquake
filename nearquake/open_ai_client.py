from openai import OpenAI
import logging

_logger = logging.getLogger(__name__)

client = OpenAI()


def generate_response(
    prompt: str, role: str = "user", model: str = "gpt-3.5-turbo"
) -> str:
    """
    Generates a response from the GPT-3.5 model based on the given role and prompt.


    :param role: The role of the user in the conversation ('user', 'system')
    :param prompt: The input prompt for the model.
    :param model: Type of GPT model to use, defaults to gpt-3.5 turbo
    :return: he content of the response generated by the model.
    """

    valid_roles = ["role", "user"]

    if role not in valid_roles:
        _logger.error(f"Invalid role: {role}. Valid options are 'role' and 'user'.")
        return f"Error: Invalid role. Please choose 'role' or 'user'."

    try:
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": role,
                    "content": prompt,
                },
            ],
        )

        return completion.choices[0].message.content

    except Exception as e:
        _logger.error(f"Unexepected error occured {e}")
        return f"Error {e}"
